{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# -*- encoding:utf-8 -*-\n",
    "import jieba.analyse\n",
    "from os import path\n",
    "from scipy.misc import imread\n",
    "from PIL import Image\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt \n",
    "from wordcloud import WordCloud, STOPWORDS, ImageColorGenerator\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "卷积 embedding word 神经网络 模型 CNN 训练 特征 情感 分类\n"
     ]
    }
   ],
   "source": [
    "#jieba的TF-IDF算法提取关键词\n",
    "d = path.dirname('.')\n",
    "content = open(path.join(d, 'testing1.txt')).read()\n",
    "   \n",
    "\n",
    "# tags extraction based on TF-IDF algorithm提取关键词十个\n",
    "tags = jieba.analyse.extract_tags(content, topK=10)\n",
    "text =\" \".join(tags) \n",
    "print(text)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#是一篇专业论文，提取关键字看看"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "关键词：\n",
      "特征 0.012808122544512782\n",
      "模型 0.012662499849293476\n",
      "word 0.009682760031966732\n",
      "进行 0.009211940460081783\n",
      "能够 0.00880385045111746\n",
      "数据 0.008481057822091674\n",
      "卷积 0.008314086461785275\n",
      "训练 0.008013659746483161\n",
      "cnn 0.007078070149296687\n",
      "embedding 0.006766569159843234\n"
     ]
    }
   ],
   "source": [
    "#textrank4zh算法提取关键词\n",
    "#-*- encoding:utf-8 -*-\n",
    "from __future__ import print_function\n",
    "\n",
    "import sys\n",
    "try:\n",
    "    reload(sys)\n",
    "    sys.setdefaultencoding('utf-8')\n",
    "except:\n",
    "    pass\n",
    "\n",
    "import codecs\n",
    "from textrank4zh import TextRank4Keyword, TextRank4Sentence\n",
    "d = path.dirname('.')\n",
    "text = open(path.join(d, 'testing1.txt')).read()\n",
    "tr4w = TextRank4Keyword()\n",
    "tr4w.analyze(text=text, lower=True, window=2)  # py2中text必须是utf8编码的str或者unicode对象，py3中必须是utf8编码的bytes或者str对象\n",
    "\n",
    "print( '关键词：' )\n",
    "for item in tr4w.get_keywords(10, word_min_len=1):\n",
    "    print(item.word, item.weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empty DataFrame\n",
      "Columns: [filepath, content, tag1, tag2, tag3, tag4]\n",
      "Index: []\n"
     ]
    }
   ],
   "source": [
    "import os,codecs,pandas\n",
    "#创建一个数据框存储数据\n",
    "tagkey=pandas.DataFrame(columns=['filepath','content','tag1','tag2','tag3','tag4'])\n",
    "print(tagkey)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid character in identifier (<ipython-input-32-535b00ed8fe8>, line 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-32-535b00ed8fe8>\"\u001b[0;36m, line \u001b[0;32m2\u001b[0m\n\u001b[0;31m    for root,dirs,files in os.walk('.\\testing1.txt',topdown=False)：\u001b[0m\n\u001b[0m                                                                  ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid character in identifier\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "for root,dirs,files in os.walk('.',topdown=False)：\n",
    "      for name in files:\n",
    "            filepath=root+'/'+name\n",
    "            f=codecs.open(d,'r','utf-8')\n",
    "            content=f.read()\n",
    "            f.close()\n",
    "            tags=jieba.analyse.extract_tags(content,topK=4)\n",
    "            tagkey.loc[len(tagkey)+1]=[filepath,content,tags[0],tags[1],tags[2],tags[3]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".\\.ipynb_checkpoints\\abstract-checkpoint.ipynb\n",
      ".\\.ipynb_checkpoints\\keyword-checkpoint.ipynb\n",
      ".\\.ipynb_checkpoints\\wordclouds-checkpoint.ipynb\n",
      ".\\.ipynb_checkpoints\\wordcloud_simple-checkpoint.ipynb\n",
      ".\\abstract.ipynb\n",
      ".\\background.jpg\n",
      ".\\background.png\n",
      ".\\keyword.ipynb\n",
      ".\\testing.txt\n",
      ".\\testing1.txt\n",
      ".\\wordcloud.png\n",
      ".\\wordclouds.ipynb\n",
      ".\\wordcloud_huangren.png\n",
      ".\\wordcloud_simple.ipynb\n",
      ".\\zxq.ttf\n",
      ".\\.ipynb_checkpoints\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "for root, dirs, files in os.walk('.', topdown=False):\n",
    "    for name in files:\n",
    "        print(os.path.join(root, name))\n",
    "    for name in dirs:\n",
    "        print(os.path.join(root, name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
