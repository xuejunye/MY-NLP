{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#textrank4zh算法提取关键词、关键词组和摘要\n",
    "#-*- encoding:utf-8 -*-\n",
    "from __future__ import print_function\n",
    "\n",
    "import sys\n",
    "try:\n",
    "    reload(sys)\n",
    "    sys.setdefaultencoding('utf-8')\n",
    "except:\n",
    "    pass\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from os import path\n",
    "import codecs\n",
    "from textrank4zh import TextRank4Keyword, TextRank4Sentence\n",
    "from PIL import Image\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "关键词：\n",
      "特征 0.012808122544512782\n",
      "模型 0.012662499849293476\n",
      "word 0.009682760031966732\n",
      "进行 0.009211940460081783\n",
      "能够 0.00880385045111746\n",
      "数据 0.008481057822091674\n",
      "卷积 0.008314086461785275\n",
      "训练 0.008013659746483161\n",
      "cnn 0.007078070149296687\n",
      "embedding 0.006766569159843234\n",
      "\n",
      "关键短语：\n",
      "模型能够\n",
      "数据特征\n",
      "模型训练\n",
      "进行卷积\n",
      "进行训练\n",
      "\n",
      "摘要：\n",
      "5 0.00866889957278515 首先，利用 Skip-Gram 模型训练出数据集中每个词的 word embedding，然后将每条样本中出现的 word embedding 组合为二维特征矩阵作为卷积神经网络的输入\n",
      "423 0.006653464400669754 基于 word embedding 的卷积神经网络模型在情感分类任务上\n",
      "387 0.006453063952152939 虽然使用维度更高的 word embedding 可以更好地对语义特征进行描述，但这也会造成卷积神经网络模型参数显著增多，从而增大过拟合的风险\n"
     ]
    }
   ],
   "source": [
    "#text = codecs.open('testing1.txt', 'r', 'utf8').read()\n",
    "   \n",
    "d = path.dirname('.')\n",
    "text = open(path.join(d, 'testing1.txt')).read()\n",
    "tr4w = TextRank4Keyword()\n",
    "\n",
    "tr4w.analyze(text=text, lower=True, window=2)  # py2中text必须是utf8编码的str或者unicode对象，py3中必须是utf8编码的bytes或者str对象\n",
    "\n",
    "print( '关键词：' )\n",
    "for item in tr4w.get_keywords(10, word_min_len=1):\n",
    "    print(item.word, item.weight)\n",
    "\n",
    "print()\n",
    "print( '关键短语：' )\n",
    "for phrase in tr4w.get_keyphrases(keywords_num=10, min_occur_num= 2):\n",
    "    print(phrase)\n",
    "\n",
    "tr4s = TextRank4Sentence()\n",
    "tr4s.analyze(text=text, lower=True, source = 'all_filters')\n",
    "\n",
    "print()\n",
    "print( '摘要：' )\n",
    "for item in tr4s.get_key_sentences(num=3):\n",
    "    print(item.index, item.weight, item.sentence)  # index是语句在文本中位置，weight是权重"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
