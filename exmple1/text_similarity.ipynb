{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\gensim-1.0.0-py3.6-win-amd64.egg\\gensim\\utils.py:855: UserWarning: detected Windows; aliasing chunkize to chunkize_serial\n",
      "  warnings.warn(\"detected Windows; aliasing chunkize to chunkize_serial\")\n",
      "Slow version of gensim.models.doc2vec is being used\n",
      "Building prefix dict from the default dictionary ...\n",
      "Loading model from cache C:\\Users\\张洪\\AppData\\Local\\Temp\\jieba.cache\n",
      "Loading model cost 0.909 seconds.\n",
      "Prefix dict has been built succesfully.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['我 喜欢 吃 番薯 ', '番薯 是 个 好 东西 ', '利用 python 进行 文本 挖掘 ']\n",
      "[['我', '喜欢', '吃', '番薯'], ['番薯', '是', '个', '好', '东西'], ['利用', 'python', '进行', '文本', '挖掘']]\n"
     ]
    }
   ],
   "source": [
    "#利用gensim做TF-IDF主题模型 \n",
    "#文本相似性分析\n",
    "import tensorflow as tf\n",
    "from gensim import corpora,models,similarities\n",
    "import jieba\n",
    "from collections import defaultdict\n",
    "\n",
    "# 1.导入句子\n",
    "sentence1 = \"我喜欢吃番薯\"\n",
    "sentence2 = \"番薯是个好东西\"\n",
    "sentence3 = \"利用python进行文本挖掘\"\n",
    "# 2.分词\n",
    "data1 = jieba.cut(sentence1)\n",
    "data2 = jieba.cut(sentence2)\n",
    "data3 = jieba.cut(sentence3)\n",
    "\n",
    "# 3.转换格式：\"词语1 词语2 词语3 … 词语n\"\n",
    "data11 = \"\"\n",
    "for item in data1:\n",
    "    data11 += item+\" \"\n",
    "data21 = \"\"\n",
    "for item in data2:\n",
    "    data21 += item+\" \"\n",
    "data31=\"\"\n",
    "for item in data3:\n",
    "    data31 += item+\" \"\n",
    "documents = [data11,data21,data31]\n",
    "texts = [[word for word in document.split()]\n",
    "        for document in documents]\n",
    "print(documents)\n",
    "print(texts)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0, 1), (1, 1), (2, 1), (3, 1)]\n"
     ]
    }
   ],
   "source": [
    "# 4.基于文本建立词典\n",
    "from gensim import corpora\n",
    "dictionary = corpora.Dictionary(texts)\n",
    "featureNum=len(dictionary.token2id.keys())#提取词典特征数\n",
    "dictionary.save(\"dictionary.txt\")#保存语料库\n",
    "\n",
    "# 5.基于词典建立新的语料库\n",
    "corpus = [dictionary.doc2bow(text) for text in texts]\n",
    "print(corpus[0])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0, 0.5646732768699807), (1, 0.5646732768699807), (2, 0.5646732768699807), (3, 0.2084041054460164)]\n",
      "[(3, 0.18147115159841573), (4, 0.49169813431045906), (5, 0.49169813431045906), (6, 0.49169813431045906), (7, 0.49169813431045906)]\n",
      "[(8, 0.4472135954999579), (9, 0.4472135954999579), (10, 0.4472135954999579), (11, 0.4472135954999579), (12, 0.4472135954999579)]\n"
     ]
    }
   ],
   "source": [
    "# 6.TF-IDF处理\n",
    "\n",
    "from gensim import models\n",
    "\n",
    "tfidf = models.TfidfModel(corpus)\n",
    "\n",
    "# 输出每个句子每个词语的tfidf值\n",
    "\n",
    "corpus_tfidf = tfidf[corpus]\n",
    "for doc in corpus_tfidf:\n",
    "    print(doc)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "查询与第1句话的相似度为:0.399284\n",
      "查询与第2句话的相似度为:0.347683\n",
      "查询与第3句话的相似度为:0.0\n"
     ]
    }
   ],
   "source": [
    "# 7.加载对比句子并整理其格式\n",
    "query = \"吃东西\"\n",
    "data4 = jieba.cut(query)\n",
    "data41 = \"\"\n",
    "for item in data4:\n",
    "    data41 += item+\" \"\n",
    "new_doc = data41\n",
    "# 8.将对比句子转换为稀疏向量\n",
    "new_vec = dictionary.doc2bow(new_doc.split())\n",
    "# 9.计算相似性\n",
    "index = similarities.SparseMatrixSimilarity(tfidf[corpus],num_features=featureNum)\n",
    "sim = index[tfidf[new_vec]]\n",
    "for i in range(len(sim)):\n",
    "    print(\"查询与第\"+str(i+1)+\"句话的相似度为:\"+str(sim[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
